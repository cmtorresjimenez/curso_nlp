{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Word2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmtorresjimenez/curso_nlp/blob/main/Word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvNCXd9Dfqe1"
      },
      "source": [
        "# Word2vec con Gensim\n",
        "\n",
        "En este cuaderno de Jupyter vas a utilizar la biblioteca [Gensim](https://radimrehurek.com/gensim/index.html) para experimentar con word2vec. Este cuaderno está enfocado en la intuición de los conceptos y no en los detalles de implementación. Este cuaderno está inspirado en esta [guía](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html).\n",
        "\n",
        "## 1. Instalación y cargar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKIqnDXXfpiz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30826a5-2acf-4e15-d3c7-9f58451e0710"
      },
      "source": [
        "!pip install --upgrade gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 22.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn7Q2jB3frOn"
      },
      "source": [
        "import gensim.downloader as api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBaT8djWkaZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95b6d0f-f440-40fc-ed88-9987a865d125"
      },
      "source": [
        "model = api.load('word2vec-google-news-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVZm7iTOoawW"
      },
      "source": [
        "## 2. Similitud de palabras\n",
        "\n",
        "En esta sección veremos cómo conseguir la similitud entre dos palabras utilizando un word embedding ya entrenado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOZfaelLoi4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf471c7-dd4b-44ac-c3b3-3a526f3a11aa"
      },
      "source": [
        "model.similarity(\"king\", \"queen\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6510957"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX-Kk9HZofuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ade92e4-ebbe-473f-fca1-1b6ded9be044"
      },
      "source": [
        "model.similarity(\"king\", \"man\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22942673"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypFK-pLrol3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a33f860-c1a6-48f5-997e-be5dcc974048"
      },
      "source": [
        "model.similarity(\"king\", \"potato\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09978465"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBWzZySFormq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4293bdc3-c9d0-475e-e655-9fe3be9d543b"
      },
      "source": [
        "model.similarity(\"king\", \"king\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GijWs_tx83W"
      },
      "source": [
        "Ahora veremos cómo encontrar las palabras con mayor similitud al conjunto de palabras especificado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytELAWBLk2-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e34f1de-12ed-4339-bdc1-52f55dabdfbf"
      },
      "source": [
        "model.most_similar([\"king\", \"queen\"], topn=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('monarch', 0.7042067050933838),\n",
              " ('kings', 0.6780861616134644),\n",
              " ('princess', 0.6731551885604858),\n",
              " ('queens', 0.6679497957229614),\n",
              " ('prince', 0.6435247659683228)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D4ZS7N3ovxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e166907-db0a-4860-9c9c-1f7ac17e34f4"
      },
      "source": [
        "model.most_similar([\"tomato\", \"carrot\"], topn=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('carrots', 0.7536594867706299),\n",
              " ('tomatoes', 0.7129638195037842),\n",
              " ('celery', 0.7025030851364136),\n",
              " ('broccoli', 0.6796350479125977),\n",
              " ('cherry_tomatoes', 0.662927508354187)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZFlxKjOyBpu"
      },
      "source": [
        "Pero incluso puedes hacer cosas interesantes como ver qué palabra no corresponde a una lista."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CrZdcBpn3pn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20a095ab-88ff-4dbe-e67e-a65ebebb8ff5"
      },
      "source": [
        "model.doesnt_match([\"summer\", \"fall\", \"spring\", \"air\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'air'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko09hZ3dqMZ1"
      },
      "source": [
        "## Ejercicios\n",
        "\n",
        "1. Usa el modelo word2vec para hacer un ranking de las siguientes 15 palabras según su similitud con las palabras \"man\" y \"woman\". Para cada par, imprime su similitud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzZ1eD3PpT-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "964659bd-4842-4f53-e7d9-b94b0ad2c7f0"
      },
      "source": [
        "words = [\n",
        "\"wife\",\n",
        "\"husband\",\n",
        "\"child\",\n",
        "\"queen\",\n",
        "\"king\",\n",
        "\"man\",\n",
        "\"woman\",\n",
        "\"birth\",\n",
        "\"doctor\",\n",
        "\"nurse\",\n",
        "\"teacher\",\n",
        "\"professor\",\n",
        "\"engineer\",\n",
        "\"scientist\",\n",
        "\"president\"]\n",
        "\n",
        "res1 = []\n",
        "res2 = []\n",
        "\n",
        "for w in words:\n",
        "  res1.append((\"man\", w, model.similarity(\"man\", w)))\n",
        "  res2.append((\"woman\", w, model.similarity(\"woman\", w)))\n",
        "\n",
        "res1 = sorted(res1,  key=lambda tup:(tup[2]), reverse=True)\n",
        "res2 = sorted(res2, key=lambda tup:(tup[2]), reverse=True)\n",
        "\n",
        "for row in res1:\n",
        "    print(*row, sep=' | ')\n",
        "\n",
        "for row in res2:\n",
        "    print(*row, sep=' | ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man | man | 1.0\n",
            "man | woman | 0.76640123\n",
            "man | husband | 0.34499747\n",
            "man | wife | 0.32920915\n",
            "man | child | 0.31633338\n",
            "man | doctor | 0.31448963\n",
            "man | nurse | 0.2547229\n",
            "man | teacher | 0.25000125\n",
            "man | king | 0.22942673\n",
            "man | queen | 0.16658202\n",
            "man | scientist | 0.15824963\n",
            "man | engineer | 0.15128928\n",
            "man | birth | 0.11078789\n",
            "man | professor | 0.09415862\n",
            "man | president | 0.028424604\n",
            "woman | woman | 1.0\n",
            "woman | man | 0.76640123\n",
            "woman | husband | 0.49281383\n",
            "woman | child | 0.47500372\n",
            "woman | wife | 0.444824\n",
            "woman | nurse | 0.44135594\n",
            "woman | doctor | 0.37945858\n",
            "woman | queen | 0.31618136\n",
            "woman | teacher | 0.31357846\n",
            "woman | birth | 0.21471293\n",
            "woman | scientist | 0.15486898\n",
            "woman | professor | 0.13077852\n",
            "woman | king | 0.12847973\n",
            "woman | engineer | 0.09435377\n",
            "woman | president | 0.062676705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKamywnxqxJJ"
      },
      "source": [
        "**2. Completa las siguientes analogías por tu cuenta (sin usar el modelo)**\n",
        "\n",
        "a. king is to throne as judge is to _\n",
        "\n",
        "b. giant is to dwarf as genius is to _\n",
        "\n",
        "c. French is to France as Spaniard is to _\n",
        "\n",
        "d. bad is to good as sad is to _\n",
        "\n",
        "e. nurse is to hospital as teacher is to _\n",
        "\n",
        "f. universe is to planet as house is to _"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar(positive=[\"king\", \"judge\"], negative=[\"throne\"], topn=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5sYOVoNqcgk",
        "outputId": "4aa3ed45-863e-444c-daee-4a92544f550f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('appeals_court', 0.5385673642158508),\n",
              " ('Judge', 0.5238491296768188),\n",
              " ('magistrate', 0.49228599667549133),\n",
              " ('court', 0.48597487807273865),\n",
              " ('appellate_court', 0.47618812322616577)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcNRxHuZrXAM"
      },
      "source": [
        "**3. Ahora completa las analogías usando un modelo word2vec**\n",
        "\n",
        "Aquí hay un ejemplo de cómo hacerlo. Puedes resolver analogías como \"A es a B como C es a _\" haciendo A + C - B. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4kF08h4qhxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1beafe-15c9-44b2-a5a3-77d3ace4b081"
      },
      "source": [
        "# man is to woman as king is to ___?\n",
        "model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118193507194519)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiPbbGsori48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050dde82-4297-4cb8-b215-ffcb4ea3f3ca"
      },
      "source": [
        "# us is to burger as italy is to ___?\n",
        "model.most_similar(positive=[\"Mexico\", \"burger\"], negative=[\"USA\"], topn=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('taco', 0.6266060471534729)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [(\"king\", \"throne\", \"judge\"),\n",
        "(\"giant\", \"dwarf\", \"genius\"),\n",
        "(\"French\", \"France\", \"Spaniard\"),\n",
        "(\"bad\", \"good\", \"sad\"),\n",
        "(\"nurse\", \"hospital\", \"teacher\"),\n",
        "(\"universe\", \"planet\", \"house\")]\n",
        "\n",
        "for x,y,z in dataset:\n",
        "  print('(',x,'-',y,') -> (',z,'-', model.most_similar(positive=[z, y], negative=[x], topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8faE05dnre_d",
        "outputId": "80230281-c779-4d49-def9-10d42790663a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "( king - throne ) -> ( judge - [('appellate_court', 0.5845253467559814), ('appeals_court', 0.5540135502815247), ('Judge', 0.529381513595581), ('presiding_judge', 0.5287210941314697), ('court', 0.5261871814727783)]\n",
            "( giant - dwarf ) -> ( genius - [('savant', 0.44152510166168213), ('brilliance', 0.4409405589103699), ('genious', 0.43906503915786743), ('prose_stylist', 0.4382379949092865), ('mathematical_genius', 0.43737608194351196)]\n",
            "( French - France ) -> ( Spaniard - [('rider_Dani_Pedrosa', 0.5646752119064331), ('Northern_Irishman', 0.5608561635017395), ('Ulsterman', 0.5575432181358337), ('Alberto_Contador_Astana', 0.5544100999832153), ('Frenchman', 0.5451046228408813)]\n",
            "( bad - good ) -> ( sad - [('wonderful', 0.6414927840232849), ('happy', 0.6154337525367737), ('great', 0.5803679823875427), ('nice', 0.5683972835540771), ('saddening', 0.5588892698287964)]\n",
            "( nurse - hospital ) -> ( teacher - [('school', 0.60170978307724), ('elementary', 0.5366939902305603), ('School', 0.516487181186676), ('schools', 0.4989596903324127), ('teachers', 0.49096396565437317)]\n",
            "( universe - planet ) -> ( house - [('bungalow', 0.5428240299224854), ('houses', 0.5330398678779602), ('residence', 0.4994273781776428), ('apartment', 0.4743870496749878), ('townhouse', 0.47175338864326477)]\n"
          ]
        }
      ]
    }
  ]
}